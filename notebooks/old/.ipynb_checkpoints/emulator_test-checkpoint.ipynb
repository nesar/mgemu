{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "f(R) gravity emulator: for fast generation of P_mg/P_lcdm\n",
    "\n",
    "\n",
    "Requires the following installations:\n",
    "\n",
    "1. gpflow\n",
    "2. scipy\n",
    "3. sklearn \n",
    "\"\"\"\n",
    "\n",
    "##### Generic packages ###############\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "import time\n",
    "import glob\n",
    "import os\n",
    "\n",
    "import pickle\n",
    "from sklearn.decomposition import PCA\n",
    "import gpflow\n",
    "import scipy.signal\n",
    "\n",
    "\n",
    "from itertools import cycle\n",
    "import matplotlib.ticker as ticker\n",
    "from matplotlib import gridspec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../models/89003GPflow_model_213Smooth_rank16snap97\n"
     ]
    }
   ],
   "source": [
    "############################# PARAMETERS ##############################\n",
    "\n",
    "dataDir = \"../../data/\" ## Data folder\n",
    "modelDir = \"../../models/\" ## Data folder\n",
    "plotsDir = \"../../plots/\" ## Data folder\n",
    "\n",
    "nRankMax = 16  ## Number of basis vectors in truncated PCA\n",
    "## Increasing nRankMax will increase emulation precision (asymptotically), but reduce the speed\n",
    "\n",
    "# del_idx = [5, 25, 4, 42]  ## Random holdouts (not used in training, reserved for validation) \n",
    "snap_ID = 97\n",
    "\n",
    "# az = np.loadtxt(dataDir + 'timestepsCOLA.txt', skiprows=1) \n",
    "\n",
    "\n",
    "############################# PARAMETERS ##############################\n",
    "\n",
    "# dataDir = \"./Data/Emulator213bins/\" ## Data folder\n",
    "# fileIn = dataDir + 'ratiosbins_' + str(snap_ID) + '.txt'\n",
    "\n",
    "\n",
    "\n",
    "# paramIn = dataDir + 'mg.design'\n",
    "# fileIn = dataDir + ['ratios.txt', 'PMG.txt'][0]\n",
    "\n",
    "\n",
    "\n",
    "# plotsDir = \"./Plots/\" ## Data folder\n",
    "# dataDir = \"./Data/Emulator_data/\" ## Data folder\n",
    "# dataDir = \"./Data/Emulator213bins/\" ## Data folder\n",
    "\n",
    "# paramIn = dataDir + 'mg.design'  ## parameter file\n",
    "\n",
    "\n",
    "\n",
    "# az = np.loadtxt(dataDir + 'timestepsCOLA.txt', skiprows=1) \n",
    "# fileIn = dataDir + 'ratiosbins_' + str(snap_ID) + '.txt'\n",
    "# z_ID = az[snap_ID, 1]\n",
    "\n",
    "GPmodel = modelDir + '89003GPflow_model_213Smooth_rank' + str(nRankMax) + 'snap' + str(snap_ID)  ## Double and single quotes are necessary\n",
    "\n",
    "print(GPmodel)\n",
    "################################# I/O #################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ############################# PARAMETERS ##############################\n",
    "# nRankMax = 4 ## Number of basis vectors in truncated PCA\n",
    "# del_idx =  [5, 25, 4, 42]  ## holdouts for testing\n",
    "# snap_ID = 97\n",
    "# ############################# INPUT FILES ##############################\n",
    "\n",
    "# plotsDir = \"./plots/\" ## Data folder\n",
    "# dataDir = \"./Data/Emulator_data/\" ## Data folder\n",
    "# dataDir = \"./Data/Emulator213bins/\" ## Data folder\n",
    "\n",
    "# paramIn = dataDir + 'mg.design'  ## parameter file\n",
    "\n",
    "\n",
    "\n",
    "# az = np.loadtxt(dataDir + 'timestepsCOLA.txt', skiprows=1) \n",
    "# fileIn = dataDir + 'ratiosbins_' + str(snap_ID) + '.txt'\n",
    "# GPmodel = '\"GP_model_213Smooth_rank' + str(nRankMax) + 'snap' + str(snap_ID) +'.RData\"'  ## Double and single quotes are necessary\n",
    "# ## DELETE the GPmodels or provide a new name if you want a new calculation\n",
    "# # num_holdout = 4\n",
    "# print(GPmodel)\n",
    "# ################################# I/O #################################\n",
    "\n",
    "\n",
    "# loadFile = np.loadtxt(fileIn)\n",
    "# PmPl_all = loadFile[:, 1:].T\n",
    "# kvals = loadFile[:,0]\n",
    "# parameter_array_all = np.loadtxt(paramIn)\n",
    "# z_ID = az[snap_ID, 1]\n",
    "\n",
    "# ########################## Deleting hold-out from training ##############\n",
    "\n",
    "\n",
    "# PmPl = np.delete(PmPl_all, del_idx, axis = 0)\n",
    "# parameter_array = np.delete(parameter_array_all, del_idx, axis = 0)\n",
    "\n",
    "\n",
    "# ####################### porting to R backend #######################\n",
    "\n",
    "# #### adding smoothing filter ########\n",
    "\n",
    "# import scipy.signal\n",
    "# yhat = scipy.signal.savgol_filter(PmPl[:,:], 51, 3) # window size 51, polynomial order 3\n",
    "\n",
    "# ####################################\n",
    "\n",
    "\n",
    "\n",
    "# nr, nc = yhat.shape\n",
    "# y_train = ro.r.matrix(yhat, nrow=nr, ncol=nc)\n",
    "\n",
    "\n",
    "# # nr, nc = PmPl[:,:].shape\n",
    "# # y_train = ro.r.matrix(PmPl[:,:], nrow=nr, ncol=nc)\n",
    "# ro.r.assign(\"y_train2\", y_train)\n",
    "# r('dim(y_train2)')\n",
    "\n",
    "# nr, nc = parameter_array[:,:].shape\n",
    "# u_train = ro.r.matrix(parameter_array[:,:], nrow=nr, ncol=nc)\n",
    "# ro.r.assign(\"u_train2\", u_train)\n",
    "# r('dim(u_train2)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loadFile = np.loadtxt(fileIn)\n",
    "# PmPl_all = loadFile[:, 1:].T\n",
    "# kvals = loadFile[:,0]\n",
    "\n",
    "\n",
    "# parameter_array_all = np.loadtxt(paramIn)\n",
    "# parameter_array_unscaled = np.loadtxt(paramIn)\n",
    "\n",
    "\n",
    "############## rescaling ##############\n",
    "\n",
    "\n",
    "def rescale01(f):\n",
    "    return np.min(f), np.max(f), (f - np.min(f)) / (np.max(f) - np.min(f))\n",
    "\n",
    "\n",
    "def scale01(fmin, fmax, f):\n",
    "    return (f - fmin) / (fmax - fmin)\n",
    "#     return f*(fmax - fmin) + fmin\n",
    "\n",
    "\n",
    "# lhd = np.zeros_like(parameter_array_all)\n",
    "# lhdmin = np.zeros_like(parameter_array_all[1])\n",
    "# lhdmax = np.zeros_like(parameter_array_all[1])\n",
    "\n",
    "# for i in range(parameter_array_all.shape[1]):\n",
    "#     lhdmin[i], lhdmax[i], lhd[:, i] = rescale01(parameter_array_all[:, i])\n",
    "   \n",
    "\n",
    "# parameter_array_all = lhd\n",
    "\n",
    "# _,_,PmPl_all = rescale01(loadFile[:, 1:].T)\n",
    "\n",
    "############## rescaling ##############\n",
    "\n",
    "\n",
    "# ## Removing hold-out test points\n",
    "# parameter_array = np.delete(parameter_array_all, del_idx, axis=0)\n",
    "# PmPl = np.delete(PmPl_all, del_idx, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../../data/'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataDir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.55e-01, 1.05e+00, 9.00e-01, 1.00e-04, 4.00e+00])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "lhdmin, lhdmax = np.loadtxt(dataDir + 'paralims.txt')\n",
    "lhdmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################# Plot the input parameter distribution ##############################\n",
    "\n",
    "allLabels = [r'${\\Omega}_m$', r'$n_s$', r'${\\sigma}_8$', r'$f_{R_0}$', r'$n$']\n",
    "\n",
    "# def rescale01(f):\n",
    "#     return (f - np.min(f)) / (np.max(f) - np.min(f))\n",
    "\n",
    "# lhd = np.zeros_like(parameter_array_all)\n",
    "# for i in range(parameter_array_all.shape[1]):\n",
    "#     _, _, lhd[:, i] = rescale01(parameter_array_all[:, i])\n",
    "    \n",
    "# def plot_params(lhd):\n",
    "#     f, a = plt.subplots(lhd.shape[1], lhd.shape[1], sharex=True, sharey=True, figsize=(12, 10) )\n",
    "#     plt.suptitle('latin hypercube design (rescaled parameters)', fontsize = 24)\n",
    "#     plt.subplots_adjust(left=None, bottom=None, right=None, top=None, wspace=None, hspace=None)\n",
    "#     plt.rcParams.update({'font.size': 8})\n",
    "\n",
    "#     for i in range(lhd.shape[1]):\n",
    "#         for j in range(i + 1):\n",
    "#             if (i != j):\n",
    "#                 a[i, j].scatter(lhd[:, i], lhd[:, j], s=5)\n",
    "#                 a[i, j].grid(True)\n",
    "                \n",
    "# #             if (j > i):\n",
    "                \n",
    "                \n",
    "#             else:\n",
    "#                 hist, bin_edges = np.histogram(lhd[:, i], density=True, bins=64)\n",
    "#                 a[i, i].text(0.4, 0.4, allLabels[i], size = 'xx-large')\n",
    "\n",
    "#                 a[i, i].bar(bin_edges[:-1], hist / hist.max(), width=0.2, alpha = 0.1)\n",
    "\n",
    "#     for i in range(lhd.shape[1]):\n",
    "#         for j in range(i + 1, lhd.shape[1]):\n",
    "\n",
    "#             plt.delaxes(a[i][j])\n",
    "#     plt.show()\n",
    "\n",
    "\n",
    "# plot_params(lhd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ########################### PCA ###################################\n",
    "# def PCA_decomp():\n",
    "# #     Dicekriging = importr('DiceKriging')\n",
    "#     r('require(foreach)')\n",
    "#     ro.r.assign(\"nrankmax\", nRankMax)\n",
    "#     r('svd(y_train2)')\n",
    "#     r('svd_decomp2 <- svd(y_train2)')\n",
    "#     r('svd_weights2 <- svd_decomp2$u[, 1:nrankmax] %*% diag(svd_decomp2$d[1:nrankmax])')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # r('install.packages(\"DiceKriging\")')\n",
    "# Dicekriging = importr('DiceKriging')\n",
    "# Dicekriging = importr('emoa')\n",
    "# GPareto = importr('GPareto')\n",
    "# # r('remove.packages(\"GPareto\")')\n",
    "# # r('install.packages(\"GPareto\")')\n",
    "\n",
    "# r('install.packages(\"GPareto\", dependencies=TRUE, repos=\"https://cloud.r-project.org\")')\n",
    "\n",
    "# r('install.packages(\"DiceDesign\")')\n",
    "# r('install.packages(\"pbivnorm\")')\n",
    "# r('install.packages(\"rgenoud\")')\n",
    "# r('install.packages(\"rgenoud\")')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################### PCA ###################################\n",
    "# set up pca compression\n",
    "# from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "# def PCA_compress(x, nComp):\n",
    "#     # x is in shape (nCosmology, nbins)\n",
    "#     pca_model = PCA(n_components=nComp)\n",
    "#     principalComponents = pca_model.fit_transform(x)\n",
    "#     pca_bases = pca_model.components_\n",
    "\n",
    "#     print(\"original shape:   \", x.shape)\n",
    "#     print(\"transformed shape:\", principalComponents.shape)\n",
    "#     print(\"bases shape:\", pca_bases.shape)\n",
    "\n",
    "#     import pickle\n",
    "#     pickle.dump(pca_model, open(modelDir + 'GPy_PCA_model' + str(nRankMax), 'wb'))\n",
    "\n",
    "#     return pca_model, np.array(principalComponents), np.array(pca_bases)\n",
    "\n",
    "\n",
    "# ######################## GP FITTING ################################\n",
    "\n",
    "# ## Build GP models\n",
    "# # This is evaluated only once for the file name. GP fitting is not required if the file exists.\n",
    "  \n",
    "\n",
    "# def GPflow_fit(parameter_array, weights, fname= GPmodel):\n",
    "#     kern = gpflow.kernels.Matern52(input_dim = np.shape(parameter_array)[1], ARD=True)\n",
    "# #     m1 = GPy.models.GPRegression(parameter_array, weights, kernel=kern)\n",
    "#     m = gpflow.models.GPR(parameter_array, weights, kern=kern, mean_function=None)\n",
    "# #     print_summary(m)\n",
    "#     m.likelihood.variance.assign(0.01)\n",
    "# #     m.kern.lengthscales.assign([100, 100, 100, 100, 100])\n",
    "# #     m.kern.lengthscales.assign([1, 1, 1, 0.1, 0.1])\n",
    "\n",
    "# #     m.kern.lengthscales.assign([0.3, 0.1, 0.2, 0.3, 0.1])\n",
    "#     m.kern.lengthscales.assign([25, 65, 15 ,1, 1])\n",
    "\n",
    "\n",
    "# #     opt = gpflow.optimizers.Scipy()\n",
    "    \n",
    "#     opt = gpflow.train.ScipyOptimizer()\n",
    "#     opt.minimize(m)\n",
    "#     m.as_pandas_table()\n",
    "    \n",
    "#     from pathlib import Path\n",
    "\n",
    "#     print(f'GPR lengthscales =', m.kern.lengthscales.value)\n",
    "\n",
    "    \n",
    "#     path = Path(GPmodel)\n",
    "#     if path.exists():\n",
    "#         path.unlink()\n",
    "    \n",
    "#     saver = gpflow.saver.Saver()\n",
    "#     saver.save(fname + str(nRankMax), m)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################## GP PREDICTION FUNCTIONS ###############################\n",
    "\n",
    "\n",
    "def GPy_predict(para_array):\n",
    "    m1p = m1.predict_f(para_array)  # [0] is the mean and [1] the predictive\n",
    "    W_predArray = m1p[0]\n",
    "    W_varArray = m1p[1]\n",
    "    return W_predArray, W_varArray\n",
    "\n",
    "\n",
    "def Emu(para_array):\n",
    "    if ((para_fid < lhdmin).any() or (para_fid > lhdmax).any() ):\n",
    "        print('Warning: input cosmology parameters outside range of the emulator, extrapolation may not be accurate')\n",
    "    \n",
    "    if len(para_array.shape) == 1:\n",
    "#         if( (lhdmin para_array \n",
    "        para_array_rescaled = scale01(lhdmin, lhdmax, para_array)\n",
    "        W_predArray, _ = GPy_predict(np.expand_dims(para_array_rescaled, axis=0))\n",
    "        x_decoded = pca_model.inverse_transform(W_predArray)\n",
    "        return np.squeeze(x_decoded)#[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ######################## GP PREDICTION ###############################\n",
    "\n",
    "# def GP_model_load(GPmodel):\n",
    "#     GPareto = importr('GPareto')\n",
    "\n",
    "#     ro.r('''\n",
    "\n",
    "#     GPmodel <- gsub(\"to\", \"\",''' + GPmodel + ''')\n",
    "\n",
    "#     ''')\n",
    "\n",
    "#     r('''if(file.exists(GPmodel)){\n",
    "#             load(GPmodel)\n",
    "#         }else{\n",
    "#             print(\"ERROR: No trained GP file\")\n",
    "#          }''')\n",
    "#     print('Loaded: ', GPmodel)\n",
    "    \n",
    "    \n",
    "# def GP_predict(para_array):\n",
    "#     GPareto = importr('GPareto')\n",
    "\n",
    "\n",
    "#     para_array = np.expand_dims(para_array, axis=0)\n",
    "#     nr, nc = para_array.shape\n",
    "#     Br = ro.r.matrix(para_array, nrow=nr, ncol=nc)\n",
    "\n",
    "#     ro.r.assign(\"Br\", Br)\n",
    "# #     r('print(\"loaded model in R kernel: \")')\n",
    "# #     r('print(GPmodel)')\n",
    "\n",
    "#     r('wtestsvd2 <- predict_kms(models_svd2, newdata = Br , type = \"UK\")')\n",
    "#     r('reconst_s2 <- t(wtestsvd2$mean) %*% t(svd_decomp2$v[,1:nrankmax])')\n",
    "\n",
    "#     y_recon = np.array(r('reconst_s2'))\n",
    "\n",
    "#     return y_recon[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #################### PCA DECOMPOSITION DONE AGAIN ##############\n",
    "# # Dicekriging = importr('DiceKriging')\n",
    "\n",
    "# PCA_decomp()\n",
    "\n",
    "# #################### LOADING TRAINED GP MODEL ##############\n",
    "\n",
    "# GP_model_load(GPmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"Unable to open object (object 'data' doesn't exist)\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-3a9e6ca74346>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0msaver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgpflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSaver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mm1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msaver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGPmodel\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnRankMax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mctx_for_loading\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mm1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mm1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/tf_gpu/lib/python3.6/site-packages/gpflow/saver/saver.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self, pathname, context)\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpathname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mcontext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSaver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0mencoded_target\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpathname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mCoderDispatcher\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoded_target\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/tf_gpu/lib/python3.6/site-packages/gpflow/saver/serializers.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self, pathname)\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpathname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpathname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mh5file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mh5file\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/tf_gpu/lib/python3.6/site-packages/h5py/_hl/group.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    175\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid HDF5 object reference\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m             \u001b[0moid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5o\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_e\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m         \u001b[0motype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5i\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/h5o.pyx\u001b[0m in \u001b[0;36mh5py.h5o.open\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"Unable to open object (object 'data' doesn't exist)\""
     ]
    }
   ],
   "source": [
    "ctx_for_loading = gpflow.saver.SaverContext(autocompile=False)\n",
    "saver = gpflow.saver.Saver()\n",
    "\n",
    "m1 = saver.load(GPmodel + str(nRankMax), context=ctx_for_loading)\n",
    "m1.clear()\n",
    "m1.compile()\n",
    "\n",
    "pca_model = pickle.load(open(modelDir + 'GPy_PCA_model' + str(nRankMax), 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'm1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-571fc81d221e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mpara_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlhdmax\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlhdmin\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEmu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpara_fid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxscale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'log'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-18-ceb81146a894>\u001b[0m in \u001b[0;36mEmu\u001b[0;34m(para_array)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m#         if( (lhdmin para_array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mpara_array_rescaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscale01\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlhdmin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlhdmax\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpara_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mW_predArray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGPy_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpara_array_rescaled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0mx_decoded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpca_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW_predArray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_decoded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#[0]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-18-ceb81146a894>\u001b[0m in \u001b[0;36mGPy_predict\u001b[0;34m(para_array)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mGPy_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpara_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mm1p\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mm1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpara_array\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# [0] is the mean and [1] the predictive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mW_predArray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mm1p\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mW_varArray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mm1p\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'm1' is not defined"
     ]
    }
   ],
   "source": [
    "# fiducial cosmology\n",
    "\n",
    "para_fid = (lhdmax + lhdmin)/2.\n",
    "plt.plot(Emu(para_fid))\n",
    "plt.xscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #### GP POSTERIOR DRAWS and PCA RECONSTRUCTIONS ######\n",
    "\n",
    "# # m1 = GPy.models.GPRegression.load_model(modelDir + 'GPy_model_rank' +str(nRankMax)+ '.zip')\n",
    "# # pca_model = pickle.load(open(modelDir + 'PCA_model_rank'+str(nRankMax), 'rb'))\n",
    "\n",
    "# # m1 = GPy.models.GPRegression.load_model(modelDir + 'GPy_model'+ str(nRankMax) +'.zip')\n",
    "# # m1 = GPy.models.GPRegression.load_model(GPmodel + '.zip')\n",
    "\n",
    "# ctx_for_loading = gpflow.saver.SaverContext(autocompile=False)\n",
    "# saver = gpflow.saver.Saver()\n",
    "\n",
    "# m1 = saver.load(GPmodel + str(nRankMax), context=ctx_for_loading)\n",
    "# m1.clear()\n",
    "# m1.compile()\n",
    "\n",
    "# pca_model = pickle.load(open(modelDir + 'GPy_PCA_model' + str(nRankMax), 'rb'))\n",
    "\n",
    "# plt.rc('text', usetex=True)  # Slower\n",
    "# plt.rc('font', size=18)  # 18 usually\n",
    "\n",
    "# plt.figure(999, figsize=(14, 12))\n",
    "# from matplotlib import gridspec\n",
    "\n",
    "# gs = gridspec.GridSpec(2, 1, height_ratios=[3, 1])\n",
    "# gs.update(hspace=0.02, left=0.2, bottom=0.15)\n",
    "# ax0 = plt.subplot(gs[0])\n",
    "# ax1 = plt.subplot(gs[1])\n",
    "\n",
    "# ax0.set_ylabel(r'$p(x)$', fontsize=25)\n",
    "# ax1.set_xlabel(r'$x$', fontsize=25)\n",
    "# ax1.set_ylabel(r'$p_{emu}/p_{num} - 1$', fontsize = 18)\n",
    "# # ax1.set_ylim(-5e-2, 5e-2)\n",
    "\n",
    "# ax0.set_xscale('log')\n",
    "# # ax0.set_yscale('log')\n",
    "# ax1.set_xscale('log')\n",
    "\n",
    "# ax1.axhline(y=0, ls='dashed')\n",
    "\n",
    "# color_id = 0\n",
    "# for x_id in del_idx:\n",
    "#     color_id = color_id + 1\n",
    "#     time0 = time.time()\n",
    "# #     x_decoded_new = Emu(parameter_array_all[x_id], PCAmodel='PCA_model', GPmodel='GPy_model')\n",
    "#     x_decoded_new = Emu(parameter_array_unscaled[x_id])\n",
    "#     x_decoded_smooth = scipy.signal.savgol_filter(x_decoded_new , 51, 6)\n",
    "\n",
    "#     time1 = time.time()\n",
    "#     print('Time per emulation %0.5f' % (time1 - time0), ' s')\n",
    "#     ax0.plot(kvals, x_decoded_new, alpha=1.0, lw = 1.5, ls='--', label='emu', dashes=(10, 10), color=plt.cm.Set1(color_id))\n",
    "#     ax0.plot(kvals, x_decoded_smooth, alpha=1.0, lw = 1.5, ls='--', label='emu', dashes=(10, 10), color=plt.cm.Set1(color_id))\n",
    "\n",
    "# #     x_test = PmPl_all[x_id]\n",
    "#     x_test = scipy.signal.savgol_filter(PmPl_all[x_id], 51, 6)\n",
    "\n",
    "#     ax0.plot(kvals, x_test, alpha=0.4, label='real', color=plt.cm.Set1(color_id))\n",
    "\n",
    "#     ax1.plot(kvals, (x_decoded_smooth / (x_test) ) - 1, ls='--', dashes=(10, 2), color=plt.cm.Set1(color_id))\n",
    "\n",
    "\n",
    "# ax0.set_xticklabels([])\n",
    "# plt.savefig(plotsDir + 'Pemu_rank' +str(nRankMax) + '.png', figsize=(28, 24), bbox_inches=\"tight\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(GPmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##################################### TESTING ##################################\n",
    "# plt.rc('font', size=18)  # \n",
    "\n",
    "# PlotPrior = True\n",
    "\n",
    "# if PlotPrior:\n",
    "\n",
    "#     plt.figure(999, figsize=(14, 12))\n",
    "\n",
    "#     gs = gridspec.GridSpec(2, 1, height_ratios=[3, 1])\n",
    "#     gs.update(hspace=0.1, left=0.2, bottom=0.15, wspace=0.25)\n",
    "#     ax0 = plt.subplot(gs[0])\n",
    "#     ax1 = plt.subplot(gs[1])\n",
    "\n",
    "#     ax0.set_ylabel(r'$P_{MG}(k)/P_{{\\Lambda}CDM}(k)$',  fontsize = 18)\n",
    "\n",
    "#     ax1.set_xlabel(r'$k$[h/Mpc]',  fontsize = 18)\n",
    "#     ax1.axhline(y=0, ls='dashed')\n",
    "\n",
    "\n",
    "#     ax0.set_yscale('log')\n",
    "#     ax0.set_xscale('log')\n",
    "#     ax1.set_xscale('log')\n",
    "\n",
    "#     ax1.set_ylabel(r'emu/test - 1',  fontsize = 18)\n",
    "#     ax1.set_ylim(-5e-2, 5e-2)\n",
    "\n",
    "#     ax0.plot(kvals, PmPl_all.T, alpha=0.15, color='k')\n",
    "\n",
    "#     start, end = ax0.get_ylim()\n",
    "#     ax0.yaxis.set_ticks((np.arange(start, end, 0.1)))\n",
    "#     ax0.yaxis.set_major_formatter(ticker.FormatStrFormatter('%0.1f'))\n",
    "#     ax1.yaxis.set_major_formatter(ticker.FormatStrFormatter('%0.3f'))\n",
    "\n",
    "\n",
    "#     ax0.set_xlim(kvals[0], kvals[-1])\n",
    "#     ax1.set_xlim(kvals[0], kvals[-1])\n",
    "#     ax0.set_xticklabels([])\n",
    "\n",
    "\n",
    "#     color_id = 0\n",
    "#     for x_id in del_idx[1:]:\n",
    "#         color_id = color_id + 1\n",
    "\n",
    "#         time0 = time.time()\n",
    "#         x_decodedGPy = Emu(parameter_array_unscaled[x_id])  ## input parameters\n",
    "#         time1 = time.time()\n",
    "#         print('Time per emulation %0.3f' % (time1 - time0), ' s')\n",
    "#         x_test = PmPl_all[x_id]\n",
    "\n",
    "#         ax0.plot(kvals, x_decodedGPy, alpha=1.0, ls='--', lw = 1.9, dashes=(5, 5), label='emu', color=plt.cm.Set1(color_id))\n",
    "#         ax0.plot(kvals, x_test, alpha=0.7, label='test', color=plt.cm.Set1(color_id))\n",
    "\n",
    "#         ax1.plot( kvals, (x_decodedGPy[:]) / (x_test[:])  - 1, color=plt.cm.Set1(color_id))\n",
    "\n",
    "# ax0.text(0.07, 1.4, 'z = %0.2f'%z_ID, fontsize= 18, style='italic')\n",
    "\n",
    "# plt.savefig(plotsDir + \"Emu.png\",  bbox_inches=\"tight\", dpi=200)\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_decodedGPy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kvals = np.loadtxt(dataDir+'kvals.txt')\n",
    "allLabels = [r'${\\Omega}_m$', r'$n_s$', r'${\\sigma}_8$', r'$f_{R_0}$', r'$n$']\n",
    "\n",
    "\n",
    "PlotCls = True\n",
    "\n",
    "if PlotCls:\n",
    "    \n",
    "    numPlots = 5\n",
    "\n",
    "    fig, ax = plt.subplots(5,2, figsize = (15,26))\n",
    "    plt.subplots_adjust(wspace=0.25)\n",
    "    \n",
    "    allMax = lhdmin\n",
    "    allMin = lhdmax\n",
    "    allMean = (lhdmax + lhdmin)/2.0\n",
    "    Pk_mean = Emu(allMean) \n",
    "    \n",
    "    for paramNo in range(5):\n",
    "        para_range = np.linspace(allMin[paramNo], allMax[paramNo], numPlots)\n",
    "\n",
    "        lines = [\"-\",\"-.\",\"--\",\":\"]\n",
    "        linecycler = cycle(lines)\n",
    "        dashList = [(6,2),(10,1),(5,5),(3,3,2,2),(5,2,20,2)]\n",
    "        colorList = ['r', 'g', 'k', 'b', 'brown']\n",
    "\n",
    "\n",
    "        for plotID in range(numPlots):\n",
    "            para_plot = np.copy(allMean)\n",
    "            para_plot[paramNo] = para_range[plotID]  \n",
    "            x_decodedGPy = Emu(para_plot) \n",
    "            lineObj = ax[4-paramNo,0].plot(kvals, x_decodedGPy, lw= 1.5, linestyle='--', dashes=dashList[plotID], color = colorList[plotID], label = allLabels[paramNo] + ' = %.1e'%para_range[plotID])\n",
    "\n",
    "            ax[4-paramNo,0].set_xscale('log')\n",
    "            ax[4-paramNo,0].set_ylabel(r'$P_{MG}(k)/P_{{\\Lambda}CDM}(k)$')\n",
    "            ax[4-paramNo,0].set_xlabel('$k$[h/Mpc]')\n",
    "            \n",
    "            ax[4-paramNo,0].set_yticks([], minor = True)\n",
    "            ax[4-paramNo,0].legend(iter(lineObj), para_range.round(decimals=2), title = allLabels[paramNo])\n",
    "            ax[4-paramNo,0].legend()\n",
    "\n",
    "            ax[4-paramNo,1].set_xscale('log')\n",
    "            ax[4-paramNo,1].set_ylabel(r'$\\Delta f / f_0$')\n",
    "            ax[4-paramNo,1].set_xlabel('$k$[h/Mpc]')\n",
    "\n",
    "            ax[4-paramNo,1].plot(kvals, (x_decodedGPy)/(Pk_mean) - 1, lw= 1.5, linestyle='--', dashes=dashList[plotID], color = colorList[plotID], label = para_range[plotID] )\n",
    "\n",
    "\n",
    "        start, end = ax[4-paramNo, 0].get_ylim()\n",
    "        ax[4-paramNo, 0].yaxis.set_ticks( (np.arange(start, end, 0.1)))\n",
    "        ax[4-paramNo, 0].yaxis.set_major_formatter(ticker.FormatStrFormatter('%0.1f'))\n",
    "\n",
    "\n",
    "fig.savefig(plotsDir + \"sensitivity.png\",  bbox_inches=\"tight\", dpi=200)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######### CALLING THE EMULATOR ##############\n",
    "#### input arguments: (Om, ns, s8, fR0, n)\n",
    "#### output: P_mg/P_lcdm in 20 bins\n",
    "#### Example: \n",
    "\n",
    "# Emu(np.array([0.1, 1.0, 0.8, 3e-5, 1.5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#################################################################################################\n",
    "#################################################################################################\n",
    "############################################## MCMC #############################################\n",
    "#################################################################################################\n",
    "\n",
    "import emcee\n",
    "import pygtc\n",
    "\n",
    "#### parameters that define the MCMC\n",
    "\n",
    "ndim = 5\n",
    "nwalkers = 800 #600  # 500\n",
    "nrun_burn = 100  # 50 # 50  # 300\n",
    "nrun = 1000 #700  # 300  # 700\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### FAKE DATA GENERATION #####\n",
    "\n",
    "\n",
    "create_fake_fiducial = False\n",
    "\n",
    "if create_fake_fiducial:\n",
    "    dirDataIn = \"./Data/FiducialData/\"\n",
    "\n",
    "    seed = 1\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    Pk_ratio = np.loadtxt(dirDataIn + 'ratios213.txt')[:, 25].T\n",
    "    Pk_ratio = (1 + np.random.rand()/100)*Pk_ratio\n",
    "    np.savetxt(dirDataIn + 'fiducial_ratio213.txt', Pk_ratio)\n",
    "\n",
    "    cov_mat = np.zeros(shape = (Pk_ratio.shape[0], Pk_ratio.shape[0]))\n",
    "\n",
    "    for i in range(Pk_ratio.shape[0]):\n",
    "        cov_mat[i, i] = (1 + kvals[i]**2)*(1 + np.random.rand())*np.sqrt(Pk_ratio[i])/8000\n",
    "\n",
    "    np.savetxt(dirDataIn + 'fiducial_cov213.txt', cov_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #### INTERPOLATED COV MATRIX GENERATION #####\n",
    "\n",
    "\n",
    "create_cov_interpolate = True\n",
    "\n",
    "if create_cov_interpolate:\n",
    "    \n",
    "    ### We have cavariance matrix for 20 bins, convert that to 213\n",
    "        \n",
    "    dirDataIn20 = \"./Data/FiducialData/FromSims/\"\n",
    "    Pk_ratio20 = np.loadtxt(dirDataIn20 + 'ratioavg_97.txt')\n",
    "    cov_mat20 = np.loadtxt(dirDataIn20 + 'covariance_97.txt')\n",
    "\n",
    "\n",
    "    from scipy import interpolate \n",
    "\n",
    "    dataDir20 = \"./Data/Emulator_data/\" ## Data folder\n",
    "    fileIn20 = dataDir20 + 'ratios_' + str(snap_ID) + '.txt'\n",
    "\n",
    "\n",
    "    loadFile20 = np.loadtxt(fileIn20)\n",
    "    kvals20 = loadFile20[:,0]\n",
    "\n",
    "    x = kvals20\n",
    "    y = kvals20\n",
    "    z = cov_mat20\n",
    "\n",
    "    cov_mat_model = interpolate.interp2d(x, y, z, kind='cubic')\n",
    "\n",
    "    xnew = kvals\n",
    "    ynew = kvals\n",
    "\n",
    "    cov_mat213 = cov_mat_model(xnew, ynew)\n",
    "    \n",
    "    cov_mat = cov_mat213\n",
    "    \n",
    "\n",
    "    Pk_ratio_model = interpolate.CubicSpline(kvals20, Pk_ratio20[:, 1])\n",
    "    \n",
    "    Pk_ratio213 = Pk_ratio_model(kvals)\n",
    "    \n",
    "    Pk_ratio = Pk_ratio213\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(232)\n",
    "\n",
    "plt.plot(kvals, Pk_ratio213, 'x')\n",
    "plt.plot(kvals20, Pk_ratio20[:, 1], 'o')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# This import registers the 3D projection, but is otherwise unused.\n",
    "from mpl_toolkits.mplot3d import Axes3D  # noqa: F401 unused import\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from matplotlib.ticker import LinearLocator, FormatStrFormatter\n",
    "import numpy as np\n",
    "\n",
    "# %matplotlib notebook\n",
    "\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.gca(projection='3d')\n",
    "\n",
    "# Make data.\n",
    "X = kvals\n",
    "Y = kvals\n",
    "X, Y = np.meshgrid(X, Y)\n",
    "Z = cov_mat\n",
    "\n",
    "# Plot the surface.\n",
    "surf = ax.plot_surface(X, Y, Z, cmap=cm.viridis,\n",
    "                       linewidth=0, antialiased=False, alpha = 0.2)\n",
    "\n",
    "\n",
    "\n",
    "# Make data.\n",
    "X = kvals20\n",
    "Y = kvals20\n",
    "X, Y = np.meshgrid(X, Y)\n",
    "Z = cov_mat20\n",
    "\n",
    "# Plot the surface.\n",
    "surf = ax.plot_surface(X, Y, Z, cmap=cm.inferno,\n",
    "                       linewidth=0, antialiased=False, alpha = 0.4)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Customize the z axis.\n",
    "# ax.set_zlim(-1.01, 1.01)\n",
    "ax.zaxis.set_major_locator(LinearLocator(10))\n",
    "ax.zaxis.set_major_formatter(FormatStrFormatter('%.02f'))\n",
    "\n",
    "# Add a color bar which maps values to colors.\n",
    "fig.colorbar(surf, shrink=0.8, aspect=5)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kvals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## REAL DATA with ERRORS #############################\n",
    "\n",
    "# Pk_ratio = np.loadtxt(dirDataIn + 'fiducial_ratio213.txt')\n",
    "# cov_mat = np.loadtxt(dirDataIn + 'fiducial_cov213.txt')\n",
    "\n",
    "# dirDataIn = \"./Data/FiducialData/FromSims/\"\n",
    "# Pk_ratio = np.loadtxt(dirDataIn + 'ratioavg_97.txt')\n",
    "# cov_mat = np.loadtxt(dirDataIn + 'covariance_97.txt')\n",
    "\n",
    "# kvals_max = 3.2\n",
    "# kvals_cond = np.where(Pk_ratio < kvals_max)\n",
    "kvals_cond = True\n",
    "\n",
    "x = np.array(kvals)\n",
    "y = Pk_ratio\n",
    "yerr_diag = np.sqrt(np.diag(cov_mat))#[:, 0]\n",
    "\n",
    "\n",
    "\n",
    "# x = x[kvals_cond]\n",
    "# y = y[kvals_cond]\n",
    "\n",
    "yerr_diag = yerr_diag[kvals_cond][0]\n",
    "# emax = emax[ls_cond][:,ls_cond][:,0,:]\n",
    "# cov_mat =  cov_mat[:len(kvals_cond[0]), :len(kvals_cond[0])]\n",
    "## Only works if slicing is done at a corner.\n",
    "# i.e., if ls_cond corresponds to continuous array entries in l\n",
    "# icov = np.linalg.inv(cov_mat)\n",
    "\n",
    "\n",
    "icov = np.linalg.pinv(cov_mat)\n",
    "\n",
    "# Moore-Penrose pseudo-inverse of a matrix.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pk_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(34, figsize = (8, 6))\n",
    "# np.sqrt(yerr[::5])/Cl[::5]\n",
    "plt.errorbar(x[::], y[::], yerr= yerr_diag[::] , marker='o',\n",
    "       color='k',\n",
    "       ecolor='k',\n",
    "       markerfacecolor='g',\n",
    "       markersize = 2,\n",
    "       capsize=0,\n",
    "       linestyle='None')\n",
    "\n",
    "\n",
    "# plt.plot(kvals, np.loadtxt(dirDataIn + 'ratios213.txt')[:, 1:], alpha = 0.3)\n",
    "plt.plot(kvals, Pk_ratio, alpha = 0.3)\n",
    "# plt.xscale('log')\n",
    "# plt.show()\n",
    "\n",
    "plt.savefig('Plots/PowerSpect_emu.pdf')\n",
    "\n",
    "\n",
    "plt.figure(43, figsize = (7, 6))\n",
    "plt.imshow(cov_mat)\n",
    "plt.colorbar()\n",
    "# plt.show()\n",
    "\n",
    "plt.savefig('Plots/Cov_mat.pdf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kvals.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# #### Cosmological Parameters ########################################\n",
    "\n",
    "# parameter_array_all.min(axis=0)\n",
    "\n",
    "# para1 = [allLabels[0], 0.1188, 0.12, 0.155]  # Actual 0.119\n",
    "# para2 = [allLabels[1], 0.02230, 0.0215, 0.0235]\n",
    "# para3 = [allLabels[2], 0.8159, 0.7, 0.89]\n",
    "# para4 = [allLabels[3], 0.6774, 0.55, 0.85]\n",
    "# para5 = [allLabels[4], 0.9667, 0.85, 1.05]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#### Cosmological Parameters ########################################\n",
    "\n",
    "allMin = parameter_array_unscaled.min(axis=0)\n",
    "allMax = parameter_array_unscaled.max(axis=0)\n",
    "# allMean = parameter_array_all.mean(axis=0)\n",
    "# allMean = parameter_array_all[25]\n",
    "\n",
    "allMean = [0.141745, 0.9667, 0.8159, 1e-5, 1.0]\n",
    "\n",
    "\n",
    "# Ω_m*h^2=0.141745, n_s=0.9667, σ_8 = 0.8159 and for the MG part f_r0=10^-5 and n=1\n",
    "\n",
    "para1 = [allLabels[0], allMean[0], allMin[0], allMax[0]]  # Actual 0.119\n",
    "para2 = [allLabels[1], allMean[1], allMin[1], allMax[1]]\n",
    "para3 = [allLabels[2], allMean[2], allMin[2], allMax[2]]\n",
    "para4 = [allLabels[3], allMean[3], allMin[3], allMax[3]]\n",
    "para5 = [allLabels[4], allMean[4], allMin[4], allMax[4]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "para4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################### CHAIN INITIALIZATION ##########################\n",
    "\n",
    "## 2 options\n",
    "\n",
    "Uniform_init = True\n",
    "if Uniform_init:\n",
    "    # Choice 1: chain uniformly distributed in the range of the parameters\n",
    "    pos_min = np.array( [para1[2], para2[2], para3[2], para4[2], para5[2]] )\n",
    "    pos_max = np.array( [para1[3], para2[3], para3[3], para4[3], para5[3]] )\n",
    "    psize = pos_max - pos_min\n",
    "    pos0 = [pos_min + psize * np.random.rand(ndim) for i in range(nwalkers)]\n",
    "\n",
    "True_init = False\n",
    "if True_init:\n",
    "    # Choice 2: chain is initialized in a tight ball around the expected values\n",
    "    pos1 = [[para1[1] * 1.2, para2[1] * 0.8, para3[1] * 0.9, para4[1] * 1.1, para5[1] * 1.2] +\n",
    "            1e-3 * np.random.randn(ndim) for i in range(nwalkers)]\n",
    "\n",
    "MaxLikelihood_init = False\n",
    "if MaxLikelihood_init:\n",
    "    # Choice 2b: Find expected values from max likelihood and use that for chain initialization\n",
    "    # Requires likehood function below to run first\n",
    "\n",
    "    import scipy.optimize as op\n",
    "\n",
    "    nll = lambda *args: -lnlike(*args)\n",
    "    result = op.minimize(nll, [para1[1], para2[1], para3[1], para4[1], para5[1]], args=(x, y, icov))\n",
    "    p1_ml, p2_ml, p3_ml, p4_ml, p5_ml = result[\"x\"]\n",
    "    print(result['x'])\n",
    "\n",
    "    pos0 = [result['x'] + 1e-5 * np.random.randn(ndim) for i in range(nwalkers)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(pos0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pygtc.plotGTC(pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the initialization\n",
    "\n",
    "PriorPlot = False\n",
    "\n",
    "if PriorPlot:\n",
    "    fig = pygtc.plotGTC(pos0, labels=[para1[0], para2[0], para3[0], para4[0], para5[0]],\n",
    "                        range=[[para1[2], para1[3]], [para2[2], para2[3]],\n",
    "                               [para3[2], para3[3]],\n",
    "                               [para4[2], para4[3]], [para5[2], para5[3]]],\n",
    "                        truths=[para1[1], para2[1], para3[1], para4[1], para5[1]])\n",
    "    fig.set_size_inches(10, 10)\n",
    "\n",
    "######### not working #######################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# allMin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# allMax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1, p2, p3, p4, p5 = allMean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (para1[2] < p1 < para1[3] and para2[2] < p2 < para2[3] and para3[2] < p3 < para3[3] and para4[2] < p4 < para4[3] and para5[2] < p5 < para5[3]):\n",
    "        print('Success')\n",
    "print('fail')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lnprior(theta):\n",
    "    p1, p2, p3, p4, p5 = theta\n",
    "    # if 0.12 < p1 < 0.155 and 0.7 < p2 < 0.9:\n",
    "    if (para1[2] < p1 < para1[3] and para2[2] < p2 < para2[3] and para3[2] < p3 < para3[3] and para4[2] < p4 < para4[3] and para5[2] < p5 < para5[3]):\n",
    "        return 0.0\n",
    "    return -np.inf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lnprior_gauss(theta):\n",
    "    p1, p2, p3, p4, p5 = theta\n",
    "    #flat priors on b, c\n",
    "#     if not 1.0 < b < 2.0 and 1.0 < c < 2.0:\n",
    "    if not (para4[2] < p4 < para4[3] and para5[2] < p5 < para5[3]):\n",
    "        return -np.inf\n",
    "    #gaussian prior on a\n",
    "    mu_para1 = para1[1]\n",
    "    sigma_para1 = np.abs(para1[2] - para1[3])/4\n",
    "#     lnprior1 =  np.log(1.0/(np.sqrt(2*np.pi)*sigma_para1))-0.5*(p1-mu_para1)**2/sigma_para1**2\n",
    "    lnprior1 =  -0.5*(p1-mu_para1)**2/sigma_para1**2\n",
    "    \n",
    "        #gaussian prior on d\n",
    "    mu_para2 = para2[1]\n",
    "    sigma_para2 = np.abs(para2[2] - para2[3])/4\n",
    "#     lnprior2 =  np.log(1.0/(np.sqrt(2*np.pi)*sigma_para2))-0.5*(p2-mu_para2)**2/sigma_para2**2\n",
    "    lnprior2 =  -0.5*(p2-mu_para2)**2/sigma_para2**2\n",
    "    \n",
    "        #gaussian prior on e\n",
    "    mu_para3 = para3[1]\n",
    "    sigma_para3 = np.abs(para3[2] - para3[3])/4\n",
    "#     lnprior3 =  np.log(1.0/(np.sqrt(2*np.pi)*sigma_para3))-0.5*(p3-mu_para3)**2/sigma_para3**2\n",
    "    lnprior3 =  -0.5*(p3-mu_para3)**2/sigma_para3**2\n",
    "    \n",
    "    return (lnprior1 + lnprior2 + lnprior3)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lnprior([0.1, 1.1, 0.8, 3e-5, 1.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######### TEMPLATE FOR MCMC LIKELIHOOD FUNCTION #######################\n",
    "# For emcee\n",
    "\n",
    "def lnlike_diag(theta, x, y, yerr):\n",
    "    p1, p2, p3, p4, p5 = theta\n",
    "\n",
    "    new_params = np.array([p1, p2, p3, p4, p5])\n",
    "\n",
    "    model = Emu(new_params)\n",
    "    return -0.5 * (np.sum(((y - model) / yerr) ** 2.))\n",
    "#     return -0.5 * (np.sum(((y - model) / yerr) ** 2.))\n",
    "\n",
    "\n",
    "def lnlike_full(theta, x, y, icov):\n",
    "    p1, p2, p3, p4, p5 = theta\n",
    "\n",
    "    new_params = np.array([p1, p2, p3, p4, p5])\n",
    "\n",
    "    model = Emu(new_params)\n",
    "    \n",
    "    y_model = np.asarray(y-model)\n",
    "    icov = np.asarray(icov)\n",
    "    return -0.5*(y_model.dot(icov).dot(y_model))\n",
    "\n",
    "## likelihood with reduced k-values\n",
    "\n",
    "def lnlike(theta, x, y, icov):\n",
    "    p1, p2, p3, p4, p5 = theta\n",
    "    \n",
    "    kval_cut = 1.0\n",
    "    truncated_kvals = np.where(x < kval_cut)\n",
    "    \n",
    "    new_params = np.array([p1, p2, p3, p4, p5])\n",
    "\n",
    "    icov = np.asarray(icov)\n",
    "    \n",
    "    \n",
    "    model = Emu(new_params)\n",
    "    \n",
    "    model_red = model[truncated_kvals]\n",
    "    icov_red = icov[0: np.array(truncated_kvals)[0][-1] + 1, 0: np.array(truncated_kvals)[0][-1] + 1]\n",
    "    x_red = x[truncated_kvals]\n",
    "    y_red = y[truncated_kvals]\n",
    "    \n",
    "    y_model = np.asarray(y_red-model_red)\n",
    "\n",
    "    \n",
    "    loglike = -0.5*(y_model.dot(icov_red).dot(y_model))\n",
    "    return loglike"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# def lnprob(theta, x, y, yerr):\n",
    "#     lp = lnprior(theta)\n",
    "#     if not np.isfinite(lp):\n",
    "#         return -np.inf\n",
    "#     # return lp + lnlike_diag(theta, x, y, yerr)\n",
    "#     return lp + lnlike(theta, x, y, yerr)\n",
    "\n",
    "\n",
    "def lnprob(theta, x, y, yerr):\n",
    "    lp = lnprior_gauss(theta)\n",
    "#     lp = lnprior(theta)\n",
    "\n",
    "    if not np.isfinite(lp):\n",
    "        return -np.inf\n",
    "    # return lp + lnlike_diag(theta, x, y, yerr)\n",
    "    return lp + lnlike(theta, x, y, yerr)\n",
    "############################# PARAMETERS ##############################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "######### MCMC #######################\n",
    "\n",
    "\n",
    "## Sample implementation :\n",
    "# http://eso-python.github.io/ESOPythonTutorials/ESOPythonDemoDay8_MCMC_with_emcee.html\n",
    "# https://users.obs.carnegiescience.edu/cburns/ipynbs/Emcee.html\n",
    "\n",
    "\n",
    "# Let us setup the emcee Ensemble Sampler\n",
    "# It is very simple: just one, self-explanatory line\n",
    "\n",
    "# sampler = emcee.EnsembleSampler(nwalkers, ndim, lnprob, args=(x, y, yerr_diag))\n",
    "sampler = emcee.EnsembleSampler(nwalkers, ndim, lnprob, args=(x, y, icov))\n",
    "\n",
    "###### BURIN-IN #################\n",
    "\n",
    "time0 = time.time()\n",
    "# burnin phase\n",
    "pos, prob, state = sampler.run_mcmc(pos0, nrun_burn)\n",
    "sampler.reset()\n",
    "time1 = time.time()\n",
    "print('burn-in time:', time1 - time0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "###### MCMC ##################\n",
    "time0 = time.time()\n",
    "# perform MCMC\n",
    "pos, prob, state = sampler.run_mcmc(pos, nrun)\n",
    "time1 = time.time()\n",
    "print('mcmc time:', time1 - time0)\n",
    "\n",
    "\n",
    "###########################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = sampler.flatchain\n",
    "samples.shape\n",
    "\n",
    "# samples[:, 3] = np.log10(samples[:, 3])\n",
    "\n",
    "# samples_plot = sampler.chain[:, :, :].reshape((-1, ndim))\n",
    "sampler_chain = sampler.chain[:, :, :]#.reshape((-1, ndim))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler_chain[:,:,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler_chain[:, :, 3] = np.log10(sampler_chain[:, :, 3] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "###########################################################################\n",
    "\n",
    "\n",
    "np.savetxt('Data/Chains/SamplerPCA_mcmc_ndim' + str(ndim) + '_nwalk' + str(nwalkers) + '_run' + str(\n",
    "    nrun) + '.txt', sampler_chain.reshape((-1, ndim)))\n",
    "\n",
    "####### FINAL PARAMETER ESTIMATES #######################################\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "samples_plot = np.loadtxt('Data/Chains/SamplerPCA_mcmc_ndim' + str(ndim) + '_nwalk' + str(\n",
    "    nwalkers) + '_run' + str(nrun) + '.txt')\n",
    "\n",
    "# samples = np.exp(samples)\n",
    "p1_mcmc, p2_mcmc, p3_mcmc, p4_mcmc, p5_mcmc = map(lambda v: (v[1], v[2] - v[1],\n",
    "                                                                               v[1] - v[0]) , zip(*np.percentile(samples_plot, [16, 50, 84], axis=0)))\n",
    "print('mcmc results:', p1_mcmc[0], p2_mcmc[0], p3_mcmc[0], p4_mcmc[0], p5_mcmc[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_plot[:,:2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "####### CORNER PLOT ESTIMATES #######################################\n",
    "\n",
    "CornerPlot = True\n",
    "if CornerPlot:\n",
    "\n",
    "    fig = pygtc.plotGTC(samples_plot,\n",
    "                        paramNames=[para1[0], para2[0], para3[0], r'$log_{10}($'+para4[0] + r'$)$', para5[0]],\n",
    "                        truths=[para1[1], para2[1], para3[1], np.log10(para4[1]), para5[1]],\n",
    "                        figureSize='MNRAS_page')  # , plotDensity = True, filledPlots = False,\\smoothingKernel = 0, nContourLevels=3)\n",
    "\n",
    "    fig.savefig('Plots/pygtcPCA_' + str(ndim) + '_nwalk' + str(nwalkers) + '_run' + str(\n",
    "        nrun) +  '.pdf')\n",
    "\n",
    "####### FINAL PARAMETER ESTIMATES #######################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pfits = np.array([p1_mcmc[0], p2_mcmc[0], p3_mcmc[0], 10**(p4_mcmc[0]), p5_mcmc[0]])\n",
    "fid_cosmo = np.array(allMean)\n",
    "\n",
    "plt.figure(3111, figsize = (8, 6))\n",
    "# np.sqrt(yerr[::5])/Cl[::5]\n",
    "plt.errorbar(x[::], y[::], yerr= yerr_diag[::] , marker='o',\n",
    "       color='k',\n",
    "       ecolor='k',\n",
    "       markerfacecolor='g',\n",
    "       markersize = 2,\n",
    "       capsize=0,\n",
    "       linestyle='None', alpha = 0.3, label = 'fiducial cosmology')\n",
    "\n",
    "plt.plot(x[::], Emu(fid_cosmo), label = 'emulated at fiducial cosmology')\n",
    "plt.plot(x[::], Emu(pfits), label = 'emulated at best fit')\n",
    "\n",
    "plt.xscale('log')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# import numpy\n",
    "# lnlike([0.1, 1.1, 0.8, 3e-5, 1.5], x, y, yerr_diag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lnprior([0.1, 1.1, 0.8, 3e-5, 1.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos0[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[para1[2], para2[2], para3[2], para4[2], para5[2]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samplerlnprob = (sampler.lnprobability)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(2323, figsize = (10,10))\n",
    "plt.plot(samplerlnprob.T)\n",
    "# plt.yscale('symlog')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(23)\n",
    "plt.hist(samplerlnprob[:, -1], 200, alpha = 0.4)\n",
    "plt.hist(samplerlnprob[:, -1][samplerlnprob[:, -1] > -100], 10, alpha = 0.4)\n",
    "# plt.hist(samplerlnprob[:, -1][samplerlnprob[:, -1] > -30], 10, alpha = 0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### CORNER PLOT ESTIMATES #######################################\n",
    "\n",
    "new_samples = sampler.chain[samplerlnprob[:, -1] > -110][:, :, :].reshape((-1, ndim))\n",
    "\n",
    "\n",
    "CornerPlot = True\n",
    "if CornerPlot:\n",
    "\n",
    "    fig = pygtc.plotGTC(new_samples,\n",
    "                        paramNames=[para1[0], para2[0], para3[0], r'$log_{10}($'+para4[0] + r'$)$', para5[0]],\n",
    "                        truths=[para1[1], para2[1], para3[1], np.log10(para4[1]), para5[1]],\n",
    "                        figureSize='MNRAS_page', nContourLevels = 3)# , plotDensity = True, filledPlots = True,smoothingKernel = 0, nContourLevels= 3)\n",
    "\n",
    "    fig.savefig('Plots/pygtcPCA_' + str(ndim) + '_nwalk' + str(nwalkers) + '_run' + str(\n",
    "        nrun) +  '.pdf')\n",
    "\n",
    "####### FINAL PARAMETER ESTIMATES #######################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tau = sampler.get_autocorr_time()\n",
    "# autocorr[index] = np.mean(tau)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "n = 100*np.arange(1, index+1)\n",
    "y = autocorr[:index]\n",
    "plt.plot(n, n / 100.0, \"--k\")\n",
    "plt.plot(n, y)\n",
    "plt.xlim(0, n.max())\n",
    "plt.ylim(0, y.max() + 0.1*(y.max() - y.min()))\n",
    "plt.xlabel(\"number of steps\")\n",
    "plt.ylabel(r\"mean $\\hat{\\tau}$\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the estimators for a few different chain lengths\n",
    "chain = sampler.chain#[:, :, 0].T\n",
    "\n",
    "\n",
    "N = np.exp(np.linspace(np.log(100), np.log(chain.shape[1]), 10)).astype(int)\n",
    "gw2010 = np.empty(len(N))\n",
    "new = np.empty(len(N))\n",
    "for i, n in enumerate(N):\n",
    "    gw2010[i] = autocorr_gw2010(chain[:, :n])\n",
    "    new[i] = autocorr_new(chain[:, :n])\n",
    "\n",
    "# Plot the comparisons\n",
    "plt.loglog(N, gw2010, \"o-\", label=\"G\\&W 2010\")\n",
    "plt.loglog(N, new, \"o-\", label=\"new\")\n",
    "ylim = plt.gca().get_ylim()\n",
    "plt.plot(N, N / 50.0, \"--k\", label=r\"$\\tau = N/50$\")\n",
    "plt.ylim(ylim)\n",
    "plt.xlabel(\"number of samples, $N$\")\n",
    "plt.ylabel(r\"$\\tau$ estimates\")\n",
    "plt.legend(fontsize=14);"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:tf_gpu] *",
   "language": "python",
   "name": "conda-env-tf_gpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
